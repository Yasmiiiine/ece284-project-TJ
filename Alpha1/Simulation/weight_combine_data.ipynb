{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fac33f1e57c8e97"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T08:09:32.074775Z",
     "start_time": "2025-11-30T06:13:10.550574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import time\n",
    "\n",
    "# 假设你的 QuantConv2d 等定义在 models.py 中\n",
    "# 如果 models.py 也是你自己写的，请确保里面的 tensor 也是创建在正确的 device 上\n",
    "from models import * # ==========================================\n",
    "# 1. 设备配置 (MacBook 适配核心)\n",
    "# ==========================================\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")  # Apple Silicon GPU 加速\n",
    "    elif torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\") # NVIDIA GPU\n",
    "    else:\n",
    "        return torch.device(\"cpu\")  # 传统 CPU\n",
    "\n",
    "device = get_device()\n",
    "print(f\"当前运行设备: {device}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. 模型定义 (VGG16_Part1) - 已修改保留 BN\n",
    "# ==========================================\n",
    "class VGG16_Part1(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGG16_Part1, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # --- Block 1 ---\n",
    "            QuantConv2d(3, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            QuantConv2d(64, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # --- Block 2 ---\n",
    "            QuantConv2d(64, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            QuantConv2d(128, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # --- Block 3 ---\n",
    "            QuantConv2d(128, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            QuantConv2d(256, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            QuantConv2d(256, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # --- Block 4 ---\n",
    "            QuantConv2d(256, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "            QuantConv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "            QuantConv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # --- Block 5 (修改区域) ---\n",
    "            # 原本的第一层: 512 -> 512\n",
    "            QuantConv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "\n",
    "            # ================= PART 1 核心修改: 8x8 Squeezed Layer =================\n",
    "            # 1. 适配层 (Adapter): 512 -> 8 (使用 1x1 卷积降维)\n",
    "            QuantConv2d(512, 8, kernel_size=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 2. 目标层 (Target Layer): 8 -> 8 (3x3 卷积)\n",
    "            # 【修改点】：保留 BN\n",
    "            QuantConv2d(8, 8, kernel_size=3, padding=1, bias=False), # 有BN通常不需要bias\n",
    "            nn.BatchNorm2d(8), # <--- 这里的 BN 被保留了\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 3. 恢复层 (Expand): 8 -> 512 (使用 1x1 卷积升维)\n",
    "            QuantConv2d(8, 512, kernel_size=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # ===================================================================\n",
    "\n",
    "            # Block 5 剩余部分\n",
    "            QuantConv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=1, stride=1),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# 实例化并移至对应设备 (MPS or CPU)\n",
    "model_part1 = VGG16_Part1().to(device)\n",
    "print(\"VGG16_Part1 模型构建完成。目标 8x8 层已保留 BN。\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. 权重加载函数 (适配 Mac)\n",
    "# ==========================================\n",
    "def load_pretrained_weights(model, pretrained_path):\n",
    "    if os.path.isfile(pretrained_path):\n",
    "        print(f\"=> loading checkpoint '{pretrained_path}'\")\n",
    "\n",
    "        # 【关键修改】：map_location 确保在 Mac 上能加载 CUDA 训练的权重\n",
    "        checkpoint = torch.load(pretrained_path, map_location=device)\n",
    "\n",
    "        pretrained_dict = checkpoint['state_dict']\n",
    "        model_dict = model.state_dict()\n",
    "\n",
    "        # 过滤不匹配层\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items()\n",
    "                           if k in model_dict and v.shape == model_dict[k].shape}\n",
    "\n",
    "        model_dict.update(pretrained_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "\n",
    "        print(f\"已加载预训练权重。忽略了 {len(model.state_dict()) - len(pretrained_dict)} 个不匹配的参数层。\")\n",
    "    else:\n",
    "        print(f\"在 '{pretrained_path}' 未找到 checkpoint\")\n",
    "\n",
    "PRETRAINED_PATH = \"result/VGG16_quant/model_best.pth.tar\"\n",
    "# 即使文件不存在也不报错，方便你直接运行代码测试逻辑\n",
    "if os.path.exists(PRETRAINED_PATH):\n",
    "    load_pretrained_weights(model_part1, PRETRAINED_PATH)\n",
    "else:\n",
    "    print(f\"提示: '{PRETRAINED_PATH}' 不存在，跳过加载权重，使用随机初始化。\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. 数据加载 (适配 Mac)\n",
    "# ==========================================\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "# Mac 上 num_workers 设置过大可能导致多进程错误，通常 0 (主进程) 或 2 比较稳妥\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=128, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=128, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 5. 训练循环 (适配 MPS/CPU)\n",
    "# ==========================================\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(model_part1.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20, 40], gamma=0.1)\n",
    "\n",
    "def fine_tune_advanced(model, train_loader, test_loader, epochs=50):\n",
    "    best_acc = 0\n",
    "    model.to(device) # 确保模型在 MPS/CPU\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # --- Training ---\n",
    "        model.train()\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            # 将数据移动到 Mac 支持的设备\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 更新学习率\n",
    "        scheduler.step()\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                output = model(inputs)\n",
    "                _, predicted = output.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        acc = 100. * correct / total\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] (LR: {current_lr:.5f}) -> Test Accuracy: {acc:.2f}%\")\n",
    "\n",
    "        # 保存最佳模型 (保存到 CPU 格式，兼容性最好)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            # 确保文件夹存在\n",
    "            if not os.path.exists(\"result\"):\n",
    "                os.makedirs(\"result\")\n",
    "            torch.save({'state_dict': model.state_dict()}, \"result/vgg_16_part1_best.pth.tar\")\n",
    "            print(f\"   New Best found: {best_acc:.2f}% (Saved)\")\n",
    "\n",
    "    print(f\" Advanced Fine-tuning 完成！最终最佳精度: {best_acc:.2f}%\")\n",
    "    return best_acc\n",
    "\n",
    "# 开始训练\n",
    "fine_tune_advanced(model_part1, trainloader, testloader, epochs=50)"
   ],
   "id": "52e9da77a43e18de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前运行设备: mps\n",
      "VGG16_Part1 模型构建完成。目标 8x8 层已保留 BN。\n",
      "=> loading checkpoint 'result/VGG16_quant/model_best.pth.tar'\n",
      "已加载预训练权重。忽略了 30 个不匹配的参数层。\n",
      "Epoch [1/50] (LR: 0.01000) -> Test Accuracy: 87.64%\n",
      "   New Best found: 87.64% (Saved)\n",
      "Epoch [2/50] (LR: 0.01000) -> Test Accuracy: 89.74%\n",
      "   New Best found: 89.74% (Saved)\n",
      "Epoch [3/50] (LR: 0.01000) -> Test Accuracy: 88.58%\n",
      "Epoch [4/50] (LR: 0.01000) -> Test Accuracy: 88.74%\n",
      "Epoch [5/50] (LR: 0.01000) -> Test Accuracy: 89.67%\n",
      "Epoch [6/50] (LR: 0.01000) -> Test Accuracy: 87.74%\n",
      "Epoch [7/50] (LR: 0.01000) -> Test Accuracy: 89.91%\n",
      "   New Best found: 89.91% (Saved)\n",
      "Epoch [8/50] (LR: 0.01000) -> Test Accuracy: 89.45%\n",
      "Epoch [9/50] (LR: 0.01000) -> Test Accuracy: 89.57%\n",
      "Epoch [10/50] (LR: 0.01000) -> Test Accuracy: 89.10%\n",
      "Epoch [11/50] (LR: 0.01000) -> Test Accuracy: 89.77%\n",
      "Epoch [12/50] (LR: 0.01000) -> Test Accuracy: 89.51%\n",
      "Epoch [13/50] (LR: 0.01000) -> Test Accuracy: 90.27%\n",
      "   New Best found: 90.27% (Saved)\n",
      "Epoch [14/50] (LR: 0.01000) -> Test Accuracy: 89.51%\n",
      "Epoch [15/50] (LR: 0.01000) -> Test Accuracy: 89.59%\n",
      "Epoch [16/50] (LR: 0.01000) -> Test Accuracy: 89.14%\n",
      "Epoch [17/50] (LR: 0.01000) -> Test Accuracy: 89.81%\n",
      "Epoch [18/50] (LR: 0.01000) -> Test Accuracy: 89.32%\n",
      "Epoch [19/50] (LR: 0.01000) -> Test Accuracy: 89.74%\n",
      "Epoch [20/50] (LR: 0.00100) -> Test Accuracy: 90.25%\n",
      "Epoch [21/50] (LR: 0.00100) -> Test Accuracy: 92.39%\n",
      "   New Best found: 92.39% (Saved)\n",
      "Epoch [22/50] (LR: 0.00100) -> Test Accuracy: 92.44%\n",
      "   New Best found: 92.44% (Saved)\n",
      "Epoch [23/50] (LR: 0.00100) -> Test Accuracy: 92.35%\n",
      "Epoch [24/50] (LR: 0.00100) -> Test Accuracy: 92.33%\n",
      "Epoch [25/50] (LR: 0.00100) -> Test Accuracy: 92.42%\n",
      "Epoch [26/50] (LR: 0.00100) -> Test Accuracy: 92.30%\n",
      "Epoch [27/50] (LR: 0.00100) -> Test Accuracy: 92.45%\n",
      "   New Best found: 92.45% (Saved)\n",
      "Epoch [28/50] (LR: 0.00100) -> Test Accuracy: 92.51%\n",
      "   New Best found: 92.51% (Saved)\n",
      "Epoch [29/50] (LR: 0.00100) -> Test Accuracy: 92.51%\n",
      "Epoch [30/50] (LR: 0.00100) -> Test Accuracy: 92.55%\n",
      "   New Best found: 92.55% (Saved)\n",
      "Epoch [31/50] (LR: 0.00100) -> Test Accuracy: 92.69%\n",
      "   New Best found: 92.69% (Saved)\n",
      "Epoch [32/50] (LR: 0.00100) -> Test Accuracy: 92.57%\n",
      "Epoch [33/50] (LR: 0.00100) -> Test Accuracy: 92.65%\n",
      "Epoch [34/50] (LR: 0.00100) -> Test Accuracy: 92.55%\n",
      "Epoch [35/50] (LR: 0.00100) -> Test Accuracy: 92.66%\n",
      "Epoch [36/50] (LR: 0.00100) -> Test Accuracy: 92.65%\n",
      "Epoch [37/50] (LR: 0.00100) -> Test Accuracy: 92.73%\n",
      "   New Best found: 92.73% (Saved)\n",
      "Epoch [38/50] (LR: 0.00100) -> Test Accuracy: 92.78%\n",
      "   New Best found: 92.78% (Saved)\n",
      "Epoch [39/50] (LR: 0.00100) -> Test Accuracy: 92.69%\n",
      "Epoch [40/50] (LR: 0.00010) -> Test Accuracy: 92.62%\n",
      "Epoch [41/50] (LR: 0.00010) -> Test Accuracy: 92.82%\n",
      "   New Best found: 92.82% (Saved)\n",
      "Epoch [42/50] (LR: 0.00010) -> Test Accuracy: 92.75%\n",
      "Epoch [43/50] (LR: 0.00010) -> Test Accuracy: 92.72%\n",
      "Epoch [44/50] (LR: 0.00010) -> Test Accuracy: 92.68%\n",
      "Epoch [45/50] (LR: 0.00010) -> Test Accuracy: 92.80%\n",
      "Epoch [46/50] (LR: 0.00010) -> Test Accuracy: 92.67%\n",
      "Epoch [47/50] (LR: 0.00010) -> Test Accuracy: 92.91%\n",
      "   New Best found: 92.91% (Saved)\n",
      "Epoch [48/50] (LR: 0.00010) -> Test Accuracy: 92.75%\n",
      "Epoch [49/50] (LR: 0.00010) -> Test Accuracy: 92.88%\n",
      "Epoch [50/50] (LR: 0.00010) -> Test Accuracy: 92.67%\n",
      " Advanced Fine-tuning 完成！最终最佳精度: 92.91%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92.91"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T14:08:02.855255Z",
     "start_time": "2025-12-01T14:07:46.155674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *  # 确保有 QuantConv2d 定义\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 1. 设备配置 (MacBook 友好)\n",
    "# ==========================================\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")  # Apple Silicon GPU\n",
    "    elif torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")  # NVIDIA GPU\n",
    "    else:\n",
    "        return torch.device(\"cpu\")  # CPU\n",
    "\n",
    "\n",
    "device = get_device()\n",
    "print(f\"[Device] 当前运行设备: {device}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 2. 模型定义 (VGG16_Part1，包含 8x8 目标层 + BN)\n",
    "# ==========================================\n",
    "class VGG16_Part1(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGG16_Part1, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # --- Block 1 ---\n",
    "            QuantConv2d(3, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            QuantConv2d(64, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # --- Block 2 ---\n",
    "            QuantConv2d(64, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            QuantConv2d(128, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # --- Block 3 ---\n",
    "            QuantConv2d(128, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            QuantConv2d(256, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            QuantConv2d(256, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # --- Block 4 ---\n",
    "            QuantConv2d(256, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "            QuantConv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "            QuantConv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # --- Block 5 (修改区域) ---\n",
    "            QuantConv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "\n",
    "            # 1. 适配层: 512 -> 8\n",
    "            QuantConv2d(512, 8, kernel_size=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 2. 目标 8x8 层: 8 -> 8 (保留 BN)\n",
    "            QuantConv2d(8, 8, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 3. 恢复层: 8 -> 512\n",
    "            QuantConv2d(8, 512, kernel_size=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # Block 5 剩余部分\n",
    "            QuantConv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=1, stride=1),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model_part1 = VGG16_Part1().to(device)\n",
    "print(\"[Model] VGG16_Part1 构建完成，8x8 目标层 + BN 就绪。\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. 加载预训练权重（可选）\n",
    "#    可以用你 >90% 的 VGG16_quant 结果作为初始化\n",
    "# ==========================================\n",
    "def load_pretrained_weights(model, pretrained_path):\n",
    "    if os.path.isfile(pretrained_path):\n",
    "        print(f\"=> loading checkpoint '{pretrained_path}'\")\n",
    "        checkpoint = torch.load(pretrained_path, map_location=device)\n",
    "        pretrained_dict = checkpoint['state_dict']\n",
    "        model_dict = model.state_dict()\n",
    "\n",
    "        # 只加载名字匹配 & shape 匹配的层，其余保持随机初始化\n",
    "        filtered = {\n",
    "            k: v for k, v in pretrained_dict.items()\n",
    "            if k in model_dict and v.shape == model_dict[k].shape\n",
    "        }\n",
    "        model_dict.update(filtered)\n",
    "        model.load_state_dict(model_dict)\n",
    "        print(f\"=> 预训练权重加载完成，匹配并加载了 {len(filtered)} 层参数。\")\n",
    "    else:\n",
    "        print(f\"[WARN] 预训练权重 '{pretrained_path}' 不存在，使用随机初始化。\")\n",
    "\n",
    "\n",
    "# 你可以把这个路径改成自己已有的 VGG16 模型\n",
    "PRETRAINED_PATH = \"result/VGG16_quant/model_best.pth.tar\"\n",
    "load_pretrained_weights(model_part1, PRETRAINED_PATH)\n",
    "\n",
    "# ==========================================\n",
    "# 4. CIFAR-10 数据（Mac 友好 num_workers）\n",
    "# ==========================================\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.491, 0.482, 0.447],\n",
    "    std=[0.247, 0.243, 0.262]\n",
    ")\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=128, shuffle=True, num_workers=2\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=128, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 5. (可选) fine-tune，默认不调用\n",
    "# ==========================================\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(\n",
    "    model_part1.parameters(), lr=0.01,\n",
    "    momentum=0.9, weight_decay=5e-4\n",
    ")\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, milestones=[20, 40], gamma=0.1\n",
    ")\n",
    "\n",
    "\n",
    "def fine_tune_advanced(model, train_loader, test_loader, epochs=50):\n",
    "    best_acc = 0.0\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "        # 验证\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "        acc = 100. * correct / total\n",
    "        print(f\"[Epoch {epoch + 1}/{epochs}] LR={current_lr:.5f}, TestAcc={acc:.2f}%\")\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            if not os.path.exists(\"result\"):\n",
    "                os.makedirs(\"result\")\n",
    "            torch.save({'state_dict': model.state_dict()},\n",
    "                       \"result/vgg_16_part1_best.pth.tar\")\n",
    "            print(f\"  -> New Best: {best_acc:.2f}% (saved)\")\n",
    "    print(f\"[Train Done] Best Acc: {best_acc:.2f}%\")\n",
    "    return best_acc\n",
    "\n",
    "\n",
    "# 如需重新训练 Part1，可以解开这一行：\n",
    "# fine_tune_advanced(model_part1, trainloader, testloader, epochs=50)\n",
    "\n",
    "# ==========================================\n",
    "# 6. BN 融合 + weight-combine α + 导出 int input/weight/output\n",
    "# ==========================================\n",
    "class SaveInput:\n",
    "    def __init__(self):\n",
    "        self.inputs = []\n",
    "\n",
    "    def __call__(self, module, module_in):\n",
    "        self.inputs.append(module_in[0].detach())\n",
    "\n",
    "    def clear(self):\n",
    "        self.inputs = []\n",
    "\n",
    "\n",
    "def find_8x8_conv_and_bn(model: nn.Module):\n",
    "    conv_8x8 = None\n",
    "    bn_after = None\n",
    "    conv_idx = None\n",
    "\n",
    "    for idx, m in enumerate(model.features):\n",
    "        if isinstance(m, QuantConv2d) and m.in_channels == 8 and m.out_channels == 8:\n",
    "            conv_8x8 = m\n",
    "            conv_idx = idx\n",
    "            if idx + 1 < len(model.features) and isinstance(model.features[idx + 1], nn.BatchNorm2d):\n",
    "                bn_after = model.features[idx + 1]\n",
    "            break\n",
    "\n",
    "    if conv_8x8 is None or bn_after is None:\n",
    "        raise RuntimeError(\"未找到 8x8 QuantConv2d 及其后续 BN(8)，请检查网络结构。\")\n",
    "\n",
    "    print(f\"[INFO] Found target 8x8 conv at features[{conv_idx}] and BN at features[{conv_idx + 1}].\")\n",
    "    return conv_8x8, bn_after, conv_idx\n",
    "\n",
    "\n",
    "def fuse_conv_bn_1x(conv: nn.Conv2d, bn: nn.BatchNorm2d):\n",
    "    w = conv.weight.detach()\n",
    "    if conv.bias is None:\n",
    "        b = torch.zeros(w.size(0), device=w.device, dtype=w.dtype)\n",
    "    else:\n",
    "        b = conv.bias.detach()\n",
    "\n",
    "    running_mean = bn.running_mean.detach()\n",
    "    running_var = bn.running_var.detach()\n",
    "    gamma = bn.weight.detach()\n",
    "    beta = bn.bias.detach()\n",
    "    eps = bn.eps\n",
    "\n",
    "    std = torch.sqrt(running_var + eps)\n",
    "    w_fused = w * (gamma / std).reshape(-1, 1, 1, 1)\n",
    "    b_fused = (b - running_mean) * (gamma / std) + beta\n",
    "    return w_fused, b_fused\n",
    "\n",
    "\n",
    "def quantize_unsigned(x: torch.Tensor, bits: int):\n",
    "    qmax = 2 ** bits - 1\n",
    "    x_clamped = torch.clamp(x, min=0.0)\n",
    "    max_val = x_clamped.max().clamp(min=1e-8)\n",
    "    scale = max_val / qmax\n",
    "    x_int = torch.round(x_clamped / scale).clamp(0, qmax).to(torch.int32)\n",
    "    return x_int, scale\n",
    "\n",
    "\n",
    "def quantize_signed(x: torch.Tensor, bits: int):\n",
    "    qmax = 2 ** (bits - 1) - 1\n",
    "    qmin = -2 ** (bits - 1)\n",
    "    max_abs = x.abs().max().clamp(min=1e-8)\n",
    "    scale = max_abs / qmax\n",
    "    x_int = torch.round(x / scale).clamp(qmin, qmax).to(torch.int32)\n",
    "    return x_int, scale\n",
    "\n",
    "\n",
    "def export_8x8_layer_with_weight_combine_alpha(\n",
    "        model: nn.Module,\n",
    "        data_loader,\n",
    "        device,\n",
    "        bits_w: int = 4,\n",
    "        bits_a: int = 4,\n",
    "        bits_out: int = 16,\n",
    "        alpha: float = 1.0,\n",
    "        out_dir: str = \"part3_8x8_fused\"\n",
    "):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # 1) 找到 8x8 conv 和其 BN\n",
    "    conv_8x8, bn_8x8, conv_idx = find_8x8_conv_and_bn(model)\n",
    "\n",
    "    # 2) hook 目标层的输入\n",
    "    hook = SaveInput()\n",
    "    handle = conv_8x8.register_forward_pre_hook(hook)\n",
    "\n",
    "    dataiter = iter(data_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    images = images.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _ = model(images)\n",
    "\n",
    "    handle.remove()\n",
    "\n",
    "    if len(hook.inputs) == 0:\n",
    "        raise RuntimeError(\"Hook 没捕获到目标层输入，请检查 hook。\")\n",
    "\n",
    "    # 取 batch 中第一张的输入: [1, 8, H, W]\n",
    "    x_in = hook.inputs[0][0:1].contiguous()\n",
    "    print(f\"[INFO] Captured target layer input shape: {x_in.shape}\")\n",
    "\n",
    "    # 3) Conv + BN 融合\n",
    "    w_fused, b_fused = fuse_conv_bn_1x(conv_8x8, bn_8x8)\n",
    "    print(f\"[INFO] Fused weight shape: {w_fused.shape}, bias shape: {b_fused.shape}\")\n",
    "\n",
    "    # 4) 引入 weight-combine α（真正利用 α 的地方）\n",
    "    w_fused_alpha = alpha * w_fused\n",
    "    print(f\"[INFO] Apply weight-combine alpha = {alpha}\")\n",
    "\n",
    "    # 5) 量化激活 & 权重\n",
    "    x_int, scale_a = quantize_unsigned(x_in, bits=bits_a)\n",
    "    w_int, scale_w = quantize_signed(w_fused_alpha, bits=bits_w)\n",
    "\n",
    "    print(f\"[INFO] scale_a={scale_a:.6e}, scale_w={scale_w:.6e}\")\n",
    "\n",
    "    # 还原实数用于卷积\n",
    "    x_q = (x_int.float() * scale_a).to(device)\n",
    "    w_q = (w_int.float() * scale_w).to(device)\n",
    "    b_q = b_fused.to(device)\n",
    "\n",
    "    # 6) 搭建等效 Conv2d 并前向\n",
    "    conv_sim = nn.Conv2d(\n",
    "        in_channels=8,\n",
    "        out_channels=8,\n",
    "        kernel_size=3,\n",
    "        padding=1,\n",
    "        bias=True\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        conv_sim.weight.copy_(w_q)\n",
    "        conv_sim.bias.copy_(b_q)\n",
    "\n",
    "        y_ref = conv_sim(x_q)\n",
    "        y_ref = torch.relu(y_ref)\n",
    "        y_int, scale_y = quantize_signed(y_ref, bits=bits_out)\n",
    "\n",
    "    print(f\"[INFO] Output shape: {y_ref.shape}, scale_y={scale_y:.6e}\")\n",
    "\n",
    "    # 7) 导出为 int txt\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    input_np = x_int.cpu().numpy().astype(np.int32).ravel()\n",
    "    weight_np = w_int.cpu().numpy().astype(np.int32).ravel()\n",
    "    output_np = y_int.cpu().numpy().astype(np.int32).ravel()\n",
    "\n",
    "    np.savetxt(os.path.join(out_dir, \"input_int.txt\"), input_np, fmt='%d')\n",
    "    np.savetxt(os.path.join(out_dir, \"weight_int.txt\"), weight_np, fmt='%d')\n",
    "    np.savetxt(os.path.join(out_dir, \"output_int.txt\"), output_np, fmt='%d')\n",
    "\n",
    "    with open(os.path.join(out_dir, \"scales_alpha.txt\"), \"w\") as f:\n",
    "        f.write(f\"alpha_weight_combine = {alpha}\\n\")\n",
    "        f.write(f\"scale_activation    = {scale_a:.8e}\\n\")\n",
    "        f.write(f\"scale_weight        = {scale_w:.8e}\\n\")\n",
    "        f.write(f\"scale_output        = {scale_y:.8e}\\n\")\n",
    "\n",
    "    print(\"====================================================\")\n",
    "    print(f\"[DONE] Exported to folder: {out_dir}\")\n",
    "    print(\"  - input_int.txt  (len = {})\".format(len(input_np)))\n",
    "    print(\"  - weight_int.txt (len = {})\".format(len(weight_np)))\n",
    "    print(\"  - output_int.txt (len = {})\".format(len(output_np)))\n",
    "    print(\"  - scales_alpha.txt\")\n",
    "    print(\"====================================================\")\n",
    "\n",
    "    return {\n",
    "        \"input_int\": input_np,\n",
    "        \"weight_int\": weight_np,\n",
    "        \"output_int\": output_np,\n",
    "        \"alpha\": alpha,\n",
    "        \"scale_a\": scale_a,\n",
    "        \"scale_w\": scale_w,\n",
    "        \"scale_y\": scale_y,\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 7. 实际调用一次，输出“最后的结果”\n",
    "# ==========================================\n",
    "model_part1.eval()\n",
    "model_part1.to(device)\n",
    "\n",
    "export_info = export_8x8_layer_with_weight_combine_alpha(\n",
    "    model_part1,\n",
    "    testloader,\n",
    "    device,\n",
    "    bits_w=4,\n",
    "    bits_a=4,\n",
    "    bits_out=16,\n",
    "    alpha=0.8,  # 这里就是你要实验的 α\n",
    "    out_dir=\"part3_8x8_alpha0.8\"\n",
    ")\n",
    "\n",
    "print(\"\\n======== 最终导出结果 Summary ========\")\n",
    "print(f\"alpha_weight_combine = {export_info['alpha']}\")\n",
    "print(f\"scale_a (activation) = {export_info['scale_a']:.6e}\")\n",
    "print(f\"scale_w (weight)     = {export_info['scale_w']:.6e}\")\n",
    "print(f\"scale_y (output)     = {export_info['scale_y']:.6e}\")\n",
    "print(\"input_int[0:16]  =\", export_info[\"input_int\"][:16])\n",
    "print(\"weight_int[0:16] =\", export_info[\"weight_int\"][:16])\n",
    "print(\"output_int[0:16] =\", export_info[\"output_int\"][:16])\n",
    "print(\"======================================\")\n"
   ],
   "id": "5d3b76fe16b6a795",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Device] 当前运行设备: mps\n",
      "[Model] VGG16_Part1 构建完成，8x8 目标层 + BN 就绪。\n",
      "=> loading checkpoint 'result/VGG16_quant/model_best.pth.tar'\n",
      "=> 预训练权重加载完成，匹配并加载了 107 层参数。\n",
      "[INFO] Found target 8x8 conv at features[40] and BN at features[41].\n",
      "[INFO] Captured target layer input shape: torch.Size([1, 8, 2, 2])\n",
      "[INFO] Fused weight shape: torch.Size([8, 8, 3, 3]), bias shape: torch.Size([8])\n",
      "[INFO] Apply weight-combine alpha = 0.8\n",
      "[INFO] scale_a=1.880996e-01, scale_w=1.344979e-02\n",
      "[INFO] Output shape: torch.Size([1, 8, 2, 2]), scale_y=1.412921e-05\n",
      "====================================================\n",
      "[DONE] Exported to folder: part3_8x8_alpha0.8\n",
      "  - input_int.txt  (len = 32)\n",
      "  - weight_int.txt (len = 576)\n",
      "  - output_int.txt (len = 32)\n",
      "  - scales_alpha.txt\n",
      "====================================================\n",
      "\n",
      "======== 最终导出结果 Summary ========\n",
      "alpha_weight_combine = 0.8\n",
      "scale_a (activation) = 1.880996e-01\n",
      "scale_w (weight)     = 1.344979e-02\n",
      "scale_y (output)     = 1.412921e-05\n",
      "input_int[0:16]  = [0 0 0 0 2 1 0 0 0 0 7 5 0 0 0 0]\n",
      "weight_int[0:16] = [ 2 -5 -3  5  4 -6 -2  1 -3 -5  4  3  4 -4 -1  5]\n",
      "output_int[0:16] = [    0  3939  3044     0 12176     0     0  2686     0     0  2865 12176\n",
      " 18443  3760     0     0]\n",
      "======================================\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T14:36:33.268878Z",
     "start_time": "2025-12-01T14:36:24.647019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# 如果前面已经定义过 SaveInput 可以删掉这个重复定义\n",
    "class SaveInput:\n",
    "    def __init__(self):\n",
    "        self.inputs = []\n",
    "\n",
    "    def __call__(self, module, module_in):\n",
    "        # module_in 是 tuple，取 [0]\n",
    "        self.inputs.append(module_in[0].detach())\n",
    "\n",
    "    def clear(self):\n",
    "        self.inputs = []\n",
    "\n",
    "\n",
    "def find_8x8_conv_and_bn(model: nn.Module):\n",
    "    \"\"\"\n",
    "    在 VGG16_Part1.features 里找 in=8, out=8 的 QuantConv2d 和其后一层 BN(8)\n",
    "    \"\"\"\n",
    "    conv_8x8 = None\n",
    "    bn_8x8 = None\n",
    "    conv_idx = None\n",
    "\n",
    "    for idx, m in enumerate(model.features):\n",
    "        # 这里假设 QuantConv2d 继承自 nn.Conv2d，有 in_channels / out_channels 属性\n",
    "        if isinstance(m, QuantConv2d) and m.in_channels == 8 and m.out_channels == 8:\n",
    "            conv_8x8 = m\n",
    "            conv_idx = idx\n",
    "            # 后一层应该是 BN\n",
    "            if idx + 1 < len(model.features) and isinstance(model.features[idx + 1], nn.BatchNorm2d):\n",
    "                bn_8x8 = model.features[idx + 1]\n",
    "            break\n",
    "\n",
    "    if conv_8x8 is None or bn_8x8 is None:\n",
    "        raise RuntimeError(\"未找到 8x8 的 QuantConv2d + BN(8)，请检查 VGG16_Part1 的 Block5 结构。\")\n",
    "\n",
    "    print(f\"[INFO] Found target 8x8 conv at features[{conv_idx}] and BN at features[{conv_idx + 1}].\")\n",
    "    return conv_8x8, bn_8x8, conv_idx\n",
    "\n",
    "\n",
    "def fuse_conv_bn_1x(conv: nn.Conv2d, bn: nn.BatchNorm2d):\n",
    "    \"\"\"\n",
    "    标准 Conv+BN 融合，得到等效的 w_fused, b_fused\n",
    "    \"\"\"\n",
    "    w = conv.weight.detach()\n",
    "    if conv.bias is None:\n",
    "        b = torch.zeros(w.size(0), device=w.device, dtype=w.dtype)\n",
    "    else:\n",
    "        b = conv.bias.detach()\n",
    "\n",
    "    running_mean = bn.running_mean.detach()\n",
    "    running_var = bn.running_var.detach()\n",
    "    gamma = bn.weight.detach()\n",
    "    beta = bn.bias.detach()\n",
    "    eps = bn.eps\n",
    "\n",
    "    std = torch.sqrt(running_var + eps)\n",
    "    w_fused = w * (gamma / std).reshape(-1, 1, 1, 1)\n",
    "    b_fused = (b - running_mean) * (gamma / std) + beta\n",
    "    return w_fused, b_fused\n",
    "\n",
    "\n",
    "def quantize_unsigned(x: torch.Tensor, bits: int):\n",
    "    \"\"\"\n",
    "    无符号量化到 [0, 2^bits-1]，返回整数张量和 scale\n",
    "    \"\"\"\n",
    "    qmax = 2 ** bits - 1\n",
    "    x_clamped = torch.clamp(x, min=0.0)\n",
    "    max_val = x_clamped.max().clamp(min=1e-8)\n",
    "    scale = max_val / qmax\n",
    "    x_int = torch.round(x_clamped / scale).clamp(0, qmax).to(torch.int32)\n",
    "    return x_int, scale\n",
    "\n",
    "\n",
    "def quantize_signed(x: torch.Tensor, bits: int):\n",
    "    \"\"\"\n",
    "    对称有符号量化到 [-2^(bits-1), 2^(bits-1)-1]\n",
    "    \"\"\"\n",
    "    qmax = 2 ** (bits - 1) - 1\n",
    "    qmin = -2 ** (bits - 1)\n",
    "    max_abs = x.abs().max().clamp(min=1e-8)\n",
    "    scale = max_abs / qmax\n",
    "    x_int = torch.round(x / scale).clamp(qmin, qmax).to(torch.int32)\n",
    "    return x_int, scale\n",
    "\n",
    "\n",
    "def int_to_bin_unsigned(val: int, bits: int) -> str:\n",
    "    \"\"\"\n",
    "    无符号转指定位宽二进制字符串\n",
    "    \"\"\"\n",
    "    val = int(val)\n",
    "    if val < 0:\n",
    "        val = 0\n",
    "    if val > (1 << bits) - 1:\n",
    "        val = (1 << bits) - 1\n",
    "    return format(val & ((1 << bits) - 1), '0{}b'.format(bits))\n",
    "\n",
    "\n",
    "def int_to_bin_twos_complement(val: int, bits: int) -> str:\n",
    "    \"\"\"\n",
    "    有符号整数 -> 指定位宽二进制补码（string）\n",
    "    \"\"\"\n",
    "    val = int(val)\n",
    "    max_pos = 2 ** (bits - 1) - 1\n",
    "    min_neg = -2 ** (bits - 1)\n",
    "    if val > max_pos:\n",
    "        val = max_pos\n",
    "    if val < min_neg:\n",
    "        val = min_neg\n",
    "    if val < 0:\n",
    "        val = (1 << bits) + val\n",
    "    return format(val & ((1 << bits) - 1), '0{}b'.format(bits))\n",
    "\n",
    "\n",
    "def export_hw7_style_files_with_alpha(\n",
    "        model: nn.Module,\n",
    "        data_loader,\n",
    "        device,\n",
    "        alpha: float = 1.0,\n",
    "        bits_a: int = 4,\n",
    "        bits_w: int = 4,\n",
    "        bits_psum: int = 16,\n",
    "        nij_start: int = 0\n",
    "):\n",
    "    \"\"\"\n",
    "    作用：\n",
    "      1. 从 VGG16_Part1 的 8x8 Conv+BN 抽一张图片的输入\n",
    "      2. Conv+BN 融合得到 w_fused, b_fused\n",
    "      3. 在 w_fused 上乘 weight-combine 因子 alpha\n",
    "      4. 对激活做无符号 4bit 量化，对权重做有符号 4bit 量化\n",
    "      5. 仿照作业提供代码的方式，生成：\n",
    "           - activation.txt (4bit, row7->0, time-step 为列)\n",
    "           - weight.txt     (4bit 2’s complement, col0..7, col 内 row7->0)\n",
    "           - psum.txt       (16bit 2’s complement, time-step 为行, col7->0)\n",
    "         这里 psum 是单个 kij=0 对应的 8x8 * 8 向量 的 dot-product 结果\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # 1) 找 8x8 的 conv 和 BN\n",
    "    conv_8x8, bn_8x8, _ = find_8x8_conv_and_bn(model)\n",
    "\n",
    "    # 2) 用 hook 抓这一层的输入\n",
    "    hook = SaveInput()\n",
    "    handle = conv_8x8.register_forward_pre_hook(hook)\n",
    "\n",
    "    data_iter = iter(data_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    images = images.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _ = model(images)\n",
    "\n",
    "    handle.remove()\n",
    "\n",
    "    if len(hook.inputs) == 0:\n",
    "        raise RuntimeError(\"Hook 没有捕获到 8x8 层的输入，请检查 hook 注册位置。\")\n",
    "\n",
    "    # 取 batch 里第一张图：shape [1, 8, H, W]\n",
    "    x_in = hook.inputs[0][0:1].contiguous()\n",
    "    B, C, H, W = x_in.shape\n",
    "    assert C == 8, f\"目标层输入通道数不是 8，而是 {C}\"\n",
    "\n",
    "    print(f\"[INFO] Captured target layer input x_in shape: {x_in.shape}\")\n",
    "\n",
    "    # 3) Conv + BN 融合\n",
    "    w_fused, b_fused = fuse_conv_bn_1x(conv_8x8, bn_8x8)\n",
    "    print(f\"[INFO] Fused weight shape: {w_fused.shape}, bias shape: {b_fused.shape}\")\n",
    "\n",
    "    # 4) 引入 weight-combine alpha\n",
    "    w_fused_alpha = alpha * w_fused\n",
    "    print(f\"[INFO] Apply weight-combine alpha = {alpha}\")\n",
    "\n",
    "    # 5) 量化激活 & 权重（整数张量）\n",
    "    x_int, scale_a = quantize_unsigned(x_in, bits=bits_a)\n",
    "    w_int, scale_w = quantize_signed(w_fused_alpha, bits=bits_w)\n",
    "\n",
    "    print(f\"[INFO] scale_a (activation) = {scale_a:.6e}, scale_w (weight) = {scale_w:.6e}\")\n",
    "\n",
    "    # ==== 仿照作业代码：准备 a_tile / w_tile / psum_tile ====\n",
    "    padding = 1\n",
    "    array_size = 8\n",
    "\n",
    "    # a_int: [C=8, H, W]\n",
    "    a_int = x_int[0]  # [8, H, W] 4-bit 无符号整数\n",
    "    # 先做 zero-padding\n",
    "    a_pad = torch.zeros(C, H + 2 * padding, W + 2 * padding, device=a_int.device, dtype=a_int.dtype)\n",
    "    a_pad[:, padding:padding + H, padding:padding + W] = a_int\n",
    "    a_pad_flat = a_pad.view(C, -1)  # [8, P]\n",
    "    P = a_pad_flat.size(1)\n",
    "    print(f\"[INFO] a_pad shape: {a_pad.shape}, flattened positions P = {P}\")\n",
    "\n",
    "    # 对应作业中的 a_tile[ic_tile,:,:]，这里只有 1 个 tile\n",
    "    a_tile = a_pad_flat.unsqueeze(0)  # [1, 8, P]\n",
    "\n",
    "    # 选择 time steps 数量：模仿作业用 64，但如果 P < 64 就用 P\n",
    "    time_steps = min(64, P)\n",
    "    if nij_start + time_steps > P:\n",
    "        raise RuntimeError(f\"nij_start({nij_start}) + time_steps({time_steps}) 超过了 a_pad_flat 的长度 {P}。\")\n",
    "    # X: [8, time_steps]\n",
    "    X = a_tile[0, :, nij_start:nij_start + time_steps].to(torch.int32)\n",
    "\n",
    "    print(f\"[INFO] Will use nij in [{nij_start}, {nij_start + time_steps}) as time steps, X shape: {X.shape}\")\n",
    "\n",
    "    # 权重：w_int [8, 8, 3, 3] -> [8, 8, 9]\n",
    "    w_int_flat = w_int.view(8, 8, -1)  # [out_c=8, in_c=8, kij=9]\n",
    "    kij = 0  # 和你作业里的例子一样，先用 kij=0\n",
    "    W = w_int_flat[:, :, kij].to(torch.int32)  # [8, 8]\n",
    "    print(f\"[INFO] Selected kij={kij}, W shape: {W.shape}\")\n",
    "\n",
    "    # 计算 psum_tile：对应 m(a_tile[ic_tile,:,nij]) 的那一步\n",
    "    # 这里没有多 tile，直接 W @ X\n",
    "    # W: [8, 8], X: [8, T] -> [8, T]\n",
    "    psum_tile = W @ X  # int32 范围内足够\n",
    "    print(f\"[INFO] psum_tile shape: {psum_tile.shape}\")\n",
    "\n",
    "    # ==== 按作业的格式写 activation.txt / weight.txt / psum.txt ====\n",
    "\n",
    "    bit_precision_a = bits_a\n",
    "    bit_precision_w = bits_w\n",
    "    bit_precision_p = bits_psum\n",
    "\n",
    "    # ---------- activation.txt ----------\n",
    "    with open('activation.txt', 'w') as f_act:\n",
    "        f_act.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
    "        f_act.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
    "        f_act.write('#................#\\n')\n",
    "\n",
    "        for t in range(time_steps):  # time step\n",
    "            for j in range(array_size):  # row index\n",
    "                # 作业里是 X[7-j, i]\n",
    "                val = int(X[7 - j, t].item())\n",
    "                bin_str = int_to_bin_unsigned(val, bit_precision_a)\n",
    "                f_act.write(bin_str)\n",
    "            f_act.write('\\n')\n",
    "\n",
    "    print(\"[SAVE] activation.txt generated.\")\n",
    "\n",
    "    # ---------- weight.txt ----------\n",
    "    with open('weight.txt', 'w') as f_w:\n",
    "        f_w.write('#col0row7[msb-lsb],col0row6[msb-lst],....,col0row0[msb-lst]#\\n')\n",
    "        f_w.write('#col1row7[msb-lsb],col1row6[msb-lst],....,col1row0[msb-lst]#\\n')\n",
    "        f_w.write('#................#\\n')\n",
    "\n",
    "        # W[col, row]，作业是 val = W[col, 7-row]\n",
    "        for col in range(array_size):\n",
    "            for row in range(array_size):\n",
    "                val = int(W[col, 7 - row].item())\n",
    "                bin_str = int_to_bin_twos_complement(val, bit_precision_w)\n",
    "                f_w.write(bin_str)\n",
    "            f_w.write('\\n')\n",
    "\n",
    "    print(\"[SAVE] weight.txt generated.\")\n",
    "\n",
    "    # ---------- psum.txt ----------\n",
    "    with open('psum.txt', 'w') as f_p:\n",
    "        f_p.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "        f_p.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "        f_p.write('#................#\\n')\n",
    "\n",
    "        # 作业里：for t in range(psum_tile.size(1)):\n",
    "        #           for col in range(psum_tile.size(0)):\n",
    "        #               val = psum_tile[7-col, t]\n",
    "        for t in range(time_steps):\n",
    "            for col in range(array_size):\n",
    "                val = int(psum_tile[7 - col, t].item())\n",
    "                bin_str = int_to_bin_twos_complement(val, bit_precision_p)\n",
    "                f_p.write(bin_str)\n",
    "            f_p.write('\\n')\n",
    "\n",
    "    print(\"[SAVE] psum.txt generated.\")\n",
    "\n",
    "    # 额外存一份 scale 和 alpha 信息，方便你 debug\n",
    "    with open('scales_alpha.txt', 'w') as f_s:\n",
    "        f_s.write(f\"alpha_weight_combine = {alpha}\\n\")\n",
    "        f_s.write(f\"scale_activation     = {scale_a:.8e}\\n\")\n",
    "        f_s.write(f\"scale_weight         = {scale_w:.8e}\\n\")\n",
    "\n",
    "    print(\"==============================================\")\n",
    "    print(\"Export summary:\")\n",
    "    print(f\"  alpha = {alpha}\")\n",
    "    print(f\"  bits_a (activation) = {bits_a}, bits_w (weight) = {bits_w}, bits_psum = {bits_psum}\")\n",
    "    print(f\"  time_steps (nij count) = {time_steps}\")\n",
    "    print(\"  Files: activation.txt, weight.txt, psum.txt, scales_alpha.txt\")\n",
    "    print(\"==============================================\")\n",
    "\n",
    "    return {\n",
    "        \"alpha\": alpha,\n",
    "        \"scale_a\": scale_a,\n",
    "        \"scale_w\": scale_w,\n",
    "        \"time_steps\": time_steps,\n",
    "    }\n",
    "\n",
    "\n",
    "# ===== 实际调用一次 =====\n",
    "# 确保 model_part1, testloader, device 已在前面定义好\n",
    "model_part1.eval()\n",
    "model_part1.to(device)\n",
    "\n",
    "info = export_hw7_style_files_with_alpha(\n",
    "    model_part1,\n",
    "    testloader,\n",
    "    device,\n",
    "    alpha=0.8,  # 这里就是你想用的 weight combine α\n",
    "    bits_a=4,\n",
    "    bits_w=4,\n",
    "    bits_psum=16,\n",
    "    nij_start=0  # 如果你想模仿作业用 200，可以改成 200（前提是 P 足够大）\n",
    ")\n",
    "\n",
    "print(\"\\n[INFO] α / scale 信息：\")\n",
    "print(\"  alpha =\", info[\"alpha\"])\n",
    "print(\"  scale_a =\", info[\"scale_a\"])\n",
    "print(\"  scale_w =\", info[\"scale_w\"])\n",
    "print(\"  time_steps =\", info[\"time_steps\"])\n"
   ],
   "id": "778f599864756a4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found target 8x8 conv at features[40] and BN at features[41].\n",
      "[INFO] Captured target layer input x_in shape: torch.Size([1, 8, 2, 2])\n",
      "[INFO] Fused weight shape: torch.Size([8, 8, 3, 3]), bias shape: torch.Size([8])\n",
      "[INFO] Apply weight-combine alpha = 0.8\n",
      "[INFO] scale_a (activation) = 1.880996e-01, scale_w (weight) = 1.344979e-02\n",
      "[INFO] a_pad shape: torch.Size([8, 4, 4]), flattened positions P = 16\n",
      "[INFO] Will use nij in [0, 16) as time steps, X shape: torch.Size([8, 16])\n",
      "[INFO] Selected kij=0, W shape: torch.Size([8, 8])\n",
      "[INFO] psum_tile shape: torch.Size([8, 16])\n",
      "[SAVE] activation.txt generated.\n",
      "[SAVE] weight.txt generated.\n",
      "[SAVE] psum.txt generated.\n",
      "==============================================\n",
      "Export summary:\n",
      "  alpha = 0.8\n",
      "  bits_a (activation) = 4, bits_w (weight) = 4, bits_psum = 16\n",
      "  time_steps (nij count) = 16\n",
      "  Files: activation.txt, weight.txt, psum.txt, scales_alpha.txt\n",
      "==============================================\n",
      "\n",
      "[INFO] α / scale 信息：\n",
      "  alpha = 0.8\n",
      "  scale_a = tensor(0.1881, device='mps:0')\n",
      "  scale_w = tensor(0.0134, device='mps:0')\n",
      "  time_steps = 16\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
